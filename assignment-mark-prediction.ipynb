{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 1. Import Libraries","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np","metadata":{"id":"WNHFFv5Haeko","trusted":true,"execution":{"iopub.status.busy":"2025-04-05T15:37:52.131806Z","iopub.execute_input":"2025-04-05T15:37:52.132269Z","iopub.status.idle":"2025-04-05T15:37:56.516256Z","shell.execute_reply.started":"2025-04-05T15:37:52.132227Z","shell.execute_reply":"2025-04-05T15:37:56.515297Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Assignment marks: training set\ntrain_samples_np = np.array([78, 100, 52, 89, 92, 87, 65, 40, 78, 82, 64, 78, 98, 86, 72, 81, 94, 92, 51, 71])\ntrain_labels_np = np.array([  1,   1,  0,  1,  1,  1,  0,  0,  1,  1,  0,  1,  1,  1,  0,  1,  1,  1,  0,  0])\n\n# Assignment marks: testing set\ntest_samples_np = np.array([75, 68, 99, 82, 71, 70, 68, 84, 87, 72, 61, 92, 93, 54, 63, 45, 74, 76, 83, 91])\ntest_labels_np = np.array([  1,  0,  1,  1,  0,  0,  0,  1,  1,  0,  0,  1,  1,  0,  0,  0,  0,  1,  1,  1])","metadata":{"id":"5vap3_N1ae6E","trusted":true,"execution":{"iopub.status.busy":"2025-04-05T15:38:01.105948Z","iopub.execute_input":"2025-04-05T15:38:01.106354Z","iopub.status.idle":"2025-04-05T15:38:01.112776Z","shell.execute_reply.started":"2025-04-05T15:38:01.10632Z","shell.execute_reply":"2025-04-05T15:38:01.111607Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # print(train_samples_np)\n# for grade in train_samples_np:\n#     if grade >= 75:\n#         print(f'{grade}:1')\n#     else:\n#         print(f'{grade}:0')\n        \n#     # print(grade)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T15:42:38.820022Z","iopub.execute_input":"2025-04-05T15:42:38.820354Z","iopub.status.idle":"2025-04-05T15:42:38.82436Z","shell.execute_reply.started":"2025-04-05T15:42:38.820328Z","shell.execute_reply":"2025-04-05T15:42:38.823406Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. Define the Data loader","metadata":{}},{"cell_type":"code","source":"class SimpleDataset(Dataset):\n    \"\"\"\n    A simple dataset for the assignment marks example.\n    \"\"\"\n    def __init__(self, samples, labels):\n        self.samples = torch.tensor(samples, dtype = torch.float32) # Convert samples to float32 tensor and assign to self.samples\n        self.labels = torch.tensor(labels, dtype = torch.long) # Convert labels to long tensor and assign to self.labels\n        self.n_samples = len(self.samples) # Store the number of samples in self.n_sample\n\n    def __len__(self):\n        # Return the total number of samples\n        return self.n_samples\n\n    def __getitem__(self, index):\n        # Return the sample and label at the given index\n        return self.samples[index], self.labels[index]\n\n\n# loader = SimpleDataset(train_samples_np, train_labels_np)\n# print(loader.n_samples)\n","metadata":{"id":"pZTaCq5Kaq7h","trusted":true,"execution":{"iopub.status.busy":"2025-04-05T15:50:48.498122Z","iopub.execute_input":"2025-04-05T15:50:48.49849Z","iopub.status.idle":"2025-04-05T15:50:48.505953Z","shell.execute_reply.started":"2025-04-05T15:50:48.498463Z","shell.execute_reply":"2025-04-05T15:50:48.504838Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Rescale the samples to have a mean of 0 and a variance of 1\nscaler = StandardScaler()  # Initialize the scaler\ntrain_samples_scaled = scaler.fit_transform(train_samples_np.reshape(-1,1))  # Fit the scaler on train_samples_np and transform\ntest_samples_scaled = scaler.fit_transform(test_samples_np.reshape(-1,1))   # Transform test_samples_np using the same scaler\n\n# Create PyTorch Datasets\ntrain_dataset = SimpleDataset(train_samples_scaled, train_labels_np)  # Create SimpleDataset with train_samples_scaled and train_labels_np\ntest_dataset = SimpleDataset(test_samples_scaled, test_labels_np)  # Create SimpleDataset with test_samples_scaled and test_labels_np\n\n# Create DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=6, shuffle=True) # Create DataLoader with train_dataset, batch_size=6, shuffle=True\ntest_loader = DataLoader(test_dataset, batch_size=5, shuffle=False)   # Create DataLoader with test_dataset, batch_size=5, shuffle=False","metadata":{"id":"DhwR0ziVa6NX","trusted":true,"execution":{"iopub.status.busy":"2025-04-05T16:18:15.665543Z","iopub.execute_input":"2025-04-05T16:18:15.665888Z","iopub.status.idle":"2025-04-05T16:18:15.673933Z","shell.execute_reply.started":"2025-04-05T16:18:15.665859Z","shell.execute_reply":"2025-04-05T16:18:15.673034Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4. Define the PyTorch Model","metadata":{}},{"cell_type":"code","source":"class SimpleNN(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(SimpleNN, self).__init__()\n        self.hidden = nn.Linear(input_size, hidden_size)   # Define a Linear layer from input_size to hidden_size\n        self.sigmoid = nn.Sigmoid()  # Define a Sigmoid activation\n        self.output = nn.Linear(hidden_size, output_size)    # Define a Linear layer from hidden_size to output_size\n        self.softmax = nn.Softmax(dim=1)  # Define a Softmax activation along dimension 1\n\n    def forward(self, x):\n        x = self.hidden(x)  # Pass x through the hidden layer\n        x = self.sigmoid(x)  # Apply the sigmoid activation\n        x = self.output(x)  # Pass through the output layer\n        x = self.softmax(x)  # Apply softmax to get output probabilities\n        return x\n\n# Instantiate the model\ninput_size = 1\nhidden_size = 4\noutput_size = 2 # Two output classes\nmodel = SimpleNN(input_size, hidden_size, output_size)\n","metadata":{"id":"QAes9yKPbWPK","trusted":true,"execution":{"iopub.status.busy":"2025-04-05T16:10:21.194318Z","iopub.execute_input":"2025-04-05T16:10:21.194723Z","iopub.status.idle":"2025-04-05T16:10:21.203407Z","shell.execute_reply.started":"2025-04-05T16:10:21.194693Z","shell.execute_reply":"2025-04-05T16:10:21.202474Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5. Define Loss Function and Optimizer","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()  # Define a loss function suitable for multi-class classification (e.g., CrossEntropyLoss)\noptimizer = optim.Adam(model.parameters(), lr=0.001)  # Define an optimizer (e.g., SGD or Adam) with model parameters and learning rate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T16:10:38.743534Z","iopub.execute_input":"2025-04-05T16:10:38.743916Z","iopub.status.idle":"2025-04-05T16:10:41.26625Z","shell.execute_reply.started":"2025-04-05T16:10:38.743886Z","shell.execute_reply":"2025-04-05T16:10:41.265356Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6. Train the Model","metadata":{}},{"cell_type":"code","source":"num_epochs = 1000  # Set the number of training epochs\n\nfor epoch in range(num_epochs):\n    for inputs, labels in train_loader:\n        #print(inputs[0], labels[0])\n        \n        # Zero the gradients\n        optimizer.zero_grad()\n        \n        # Forward pass through the model to get outputs\n        outputs = model(inputs)\n\n        \n        # Compute the loss using criterion\n        loss = criterion(outputs, labels)\n        \n        # Backward pass (loss.backward)\n        loss.backward()\n        optimizer.step()\n\n\n    if (epoch + 1) % 50 == 0:\n        # Print epoch number and current loss\n        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n\nprint(\"Finished Training\")","metadata":{"id":"AiKz3UAZbc7D","outputId":"fde3587c-7e75-40f7-d154-a7fd8f0b4056","trusted":true,"execution":{"iopub.status.busy":"2025-04-05T16:22:08.728062Z","iopub.execute_input":"2025-04-05T16:22:08.728457Z","iopub.status.idle":"2025-04-05T16:22:13.666823Z","shell.execute_reply.started":"2025-04-05T16:22:08.728424Z","shell.execute_reply":"2025-04-05T16:22:13.665918Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 7. Evaluate the Model","metadata":{}},{"cell_type":"code","source":"# Set the model to evaluation mode\nmodel.eval()\nall_predicted_labels = []\nall_test_labels = []\n\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        outputs = model(inputs) # Perform a forward pass to get outputs\n\n        _, predicted = torch.max(outputs, 1)\n        all_predicted_labels.extend(predicted.numpy())\n        all_test_labels.extend(labels.numpy())\n\npredicted_labels_np = np.array(all_predicted_labels)  # Convert all_predicted_labels to a NumPy array\ntest_labels_np =  np.array(all_test_labels)       # Convert all_test_labels to a NumPy array\n\n# Print predicted and true labels\nprint(\"Predicted labels on testing set:\", predicted_labels_np)\nprint(\"True labels on testing set:\", test_labels_np)\n\n# Compute prediction error as a percentage\nprediction_error_test = np.sum(np.abs(predicted_labels_np - test_labels_np)/len(test_labels_np))*100 # Compute the average absolute error percentage\nprint(\"Prediction error on testing set:\", prediction_error_test)","metadata":{"id":"jLItJfoObiOS","outputId":"3a6b2610-91f3-417d-ae63-0218940d3143","trusted":true,"execution":{"iopub.status.busy":"2025-04-05T16:29:42.046862Z","iopub.execute_input":"2025-04-05T16:29:42.047228Z","iopub.status.idle":"2025-04-05T16:29:42.058566Z","shell.execute_reply.started":"2025-04-05T16:29:42.047198Z","shell.execute_reply":"2025-04-05T16:29:42.057679Z"}},"outputs":[],"execution_count":null}]}