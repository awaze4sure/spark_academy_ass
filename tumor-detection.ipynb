{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11289785,"sourceType":"datasetVersion","datasetId":7059226}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Tumor_Detection\n\nA machine learning model for classifying images into \"yes\" (tumor present) and \"no\" (tumor absent) categories. The model is trained on medical imaging data to detect the presence of tumors, aiming to assist in early diagnosis and treatment planning.\n","metadata":{}},{"cell_type":"markdown","source":"**Section 0: Import Libraries**\n\nWe start by importing the necessary libraries and checking for GPU availability to speed up computation, which is especially useful for image classification tasks.","metadata":{"id":"rvT8wIu-MdpW"}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom PIL import Image\nfrom collections import Counter\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import random_split\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom torch.utils.data import DataLoader\nimport os\n\n# Check for GPU availability\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint('Device:', device)","metadata":{"id":"tJtoXqJxMhkX","outputId":"556b4baf-ca28-43a8-f1e6-d28cc95350e6","trusted":true,"execution":{"iopub.status.busy":"2025-04-05T20:37:24.670485Z","iopub.execute_input":"2025-04-05T20:37:24.670789Z","iopub.status.idle":"2025-04-05T20:37:24.676461Z","shell.execute_reply.started":"2025-04-05T20:37:24.670762Z","shell.execute_reply":"2025-04-05T20:37:24.67571Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !pwd\n# !cd /kaggle/input/tumor-x\n# # !unzip Yes_No_Tumor.zip\n# !pwd\n# !rm -rf /kaggle/input/tumor-x/no","metadata":{"id":"rxuystTmMrNt","outputId":"8a2f4ac9-d449-4544-fcb4-e40f29740a69","trusted":true,"execution":{"iopub.status.busy":"2025-04-05T20:27:43.819993Z","iopub.execute_input":"2025-04-05T20:27:43.820326Z","iopub.status.idle":"2025-04-05T20:27:43.824065Z","shell.execute_reply.started":"2025-04-05T20:27:43.820301Z","shell.execute_reply":"2025-04-05T20:27:43.823296Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Define the dataset path\ndata_dir = '/kaggle/input/tumor-x/brain_tumor_dataset'\n\n# Load the dataset without transformations\ndataset = datasets.ImageFolder(root=data_dir)\n\nprint(\"Class names in order:\", dataset.classes)\n\n# Count images per class\nclass_counts = Counter([label for _, label in dataset.samples])\nprint(f'Class distribution: {class_counts}')\n\n# Print sizes of the first 5 images\nprint(\"Original sizes of the first 5 images:\")\nfor i in range(5):\n    img_path, label = dataset.samples[i]\n    with Image.open(img_path) as img:\n        print(f'Image {i}: {img.size} (Class: {dataset.classes[label]})')\n\n\n# Function to plot samples\ndef plot_samples(dataset, num_samples=3):\n    fig, axes = plt.subplots(2, num_samples, figsize=(10, 5))\n    for i, class_name in enumerate(dataset.classes):\n        class_indices = [idx for idx, (_, label) in enumerate(dataset.samples) if label == i]\n        for j in range(num_samples):\n            img_path, _ = dataset.samples[class_indices[j]]\n            img = Image.open(img_path)\n            axes[i, j].imshow(img)\n            axes[i, j].set_title(f'{class_name}')\n            axes[i, j].axis('off')\n    plt.show()\n\n# Display samples\nplot_samples(dataset)","metadata":{"id":"PPI6cQkpTgm_","outputId":"68e25da3-1468-4a83-9fd5-ef4ca9f141b8","trusted":true,"execution":{"iopub.status.busy":"2025-04-05T20:28:42.800898Z","iopub.execute_input":"2025-04-05T20:28:42.801217Z","iopub.status.idle":"2025-04-05T20:28:43.46637Z","shell.execute_reply.started":"2025-04-05T20:28:42.801189Z","shell.execute_reply":"2025-04-05T20:28:43.465556Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Section 1: Load Data**\n\nNext, we load the MRI dataset from Kaggle and explore its structure. The dataset contains images in two folders: \"yes\" (tumor) and \"no\" (no tumor).","metadata":{"id":"IrgHSeBfMsgo"}},{"cell_type":"code","source":"# Define the path to the dataset (specific to Kaggle environment)\ndata_dir = '/kaggle/input/tumor-x/brain_tumor_dataset'  # Set path to the dataset directory\n\n# Define basic transformations for loading the images\ntransform = transforms.Compose([\n    transforms.Resize((128,128)),  # Resize images to 128x128 pixels\n    transforms.ToTensor()  # Convert images to PyTorch tensors\n])\n\n# Load the dataset using ImageFolder\ndataset = datasets.ImageFolder(root=data_dir, transform=transform)  # Load dataset from data_dir with the specified transform\n\n# Split into training and testing sets (80-20 split)\ntrain_size = int(0.8 * len(dataset))\ntest_size = len(dataset) - train_size\ntrain_dataset, test_dataset = random_split(dataset, lengths=[train_size, test_size])  # Randomly split dataset into train and test sets\n\n# Explore the dataset\nprint(f'Total images: {len(dataset)}')\nprint(f'Training images: {len(train_dataset)}')\nprint(f'Testing images: {len(test_dataset)}')\nprint(f'Classes: {dataset.classes}')\n\n# Visualize a sample image\nsample_img, sample_label = train_dataset[5]\nplt.imshow(sample_img.permute(1, 2, 0))  # Display the image (make sure to permute for correct format)\nplt.title(f'Label: {\"Tumor\" if sample_label == 1 else \"No Tumor\"}')\nplt.show()","metadata":{"id":"hWexyHEGVlWq","outputId":"421d4a67-4b89-4dc9-b14a-f100d02c8f9e","trusted":true,"execution":{"iopub.status.busy":"2025-04-05T20:39:44.222044Z","iopub.execute_input":"2025-04-05T20:39:44.222486Z","iopub.status.idle":"2025-04-05T20:39:44.444915Z","shell.execute_reply.started":"2025-04-05T20:39:44.222441Z","shell.execute_reply":"2025-04-05T20:39:44.444149Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Section 2: Preprocessing**\n\nPreprocessing prepares the data for training by applying transformations like normalization and data augmentation to improve model performance.","metadata":{"id":"ho_JgWpKMtNc"}},{"cell_type":"code","source":"# Define transformations for training (with augmentation)\ntrain_transform = transforms.Compose([\n    transforms.Resize((128,128)),  # Resize images to a consistent size (e.g., 128x128)\n    transforms.RandomHorizontalFlip(), # Apply random horizontal flips\n    transforms.RandomRotation(10),  # Apply random rotations\n    transforms.ToTensor(), # Convert images to tensors\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std= [0.229, 0.224, 0.225])  # Normalize images with pre-defined mean and std values\n])\n\n# Define transformations for testing (no augmentation)\ntest_transform = transforms.Compose([\n    transforms.Resize((128,128)),  # Resize images\n    transforms.ToTensor(),  # Convert images to tensors\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std= [0.229, 0.224, 0.225])  # Normalize images\n])\n\n# Apply transformations to the datasets\ntrain_dataset.dataset.transform = train_transform\ntest_dataset.dataset.transform = test_transform\n\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size = 32, shuffle=True)  # DataLoader for training set with batch_size and shuffle=True\ntest_loader = DataLoader(test_dataset, batch_size = 32, shuffle=False)   # DataLoader for test set with batch_size and shuffle=False","metadata":{"id":"bcPjZp_1Ocxt","trusted":true,"execution":{"iopub.status.busy":"2025-04-05T20:48:04.900445Z","iopub.execute_input":"2025-04-05T20:48:04.90077Z","iopub.status.idle":"2025-04-05T20:48:04.908119Z","shell.execute_reply.started":"2025-04-05T20:48:04.900747Z","shell.execute_reply":"2025-04-05T20:48:04.907303Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Section 3: Define Hyperparameters**\n\nHyperparameters control the training process and need to be set before defining and training the model.","metadata":{"id":"6EKtxGt2MtR0"}},{"cell_type":"code","source":"batch_size = 32\nepochs = 25\nlearning_rate = 0.001","metadata":{"id":"YUFQCF3HOger","trusted":true,"execution":{"iopub.status.busy":"2025-04-05T20:48:07.853603Z","iopub.execute_input":"2025-04-05T20:48:07.853912Z","iopub.status.idle":"2025-04-05T20:48:07.858024Z","shell.execute_reply.started":"2025-04-05T20:48:07.853884Z","shell.execute_reply":"2025-04-05T20:48:07.857131Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Section 4: Define the Network**\n\nWe design a simple convolutional neural network (CNN) to classify the MRI images.","metadata":{"id":"OVVwjCNnMtW0"}},{"cell_type":"code","source":"class TumorClassifier(nn.Module):\n    def __init__(self):\n        super(TumorClassifier, self).__init__()\n        self.conv1 = nn.Conv2d(3,16, kernel_size=3, padding=1)  # First convolutional layer (input: 3 channels, output: 16)\n        self.pool = nn.MaxPool2d(2,2)   # Max pooling layer with 2x2 kernel\n        self.conv2 = nn.Conv2d(16,32, kernel_size=3, padding=1)  # Second convolutional layer (input: 16 channels, output: 32)\n        self.fc1 = nn.Linear(32*32*32, 128)    # Fully connected layer (input: flattened conv output, output: 128)\n        self.fc2 = nn.Linear(128, 2)     # Final fully connected layer for 2 output classes (binary classification) nn.Flatten()\n\n    def forward(self, x):\n        x = self.pool(torch.relu(self.conv1(x)))  # Apply relu + conv1 + pool\n        x = self.pool(torch.relu(self.conv2(x)))  # Apply relu + conv2 + pool\n        x = x.view(-1, 32*32*32)  # Flatten the tensor #try nn.Flatten()\n        x = torch.relu(self.fc1(x))  # Apply relu + fc1\n        x = self.fc2(x)  # Output layer (fc2)\n        return x\n\n# Instantiate the model and move it to the GPU if available\nmodel = TumorClassifier()  # Create instance of TumorClassifier and move to device\nmodel = model.to(\"cuda\")\nprint(model)\n\n# Define loss function and optimizer\ncriterion = nn.CrossEntropyLoss()  # Set loss function (e.g., CrossEntropyLoss)\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)  # Set optimizer (e.g., Adam with model parameters and learning rate)\n","metadata":{"id":"liZXN6Q4OjhN","outputId":"46465e96-1ee3-44af-8518-ac2ebf7f6f46","trusted":true,"execution":{"iopub.status.busy":"2025-04-05T21:00:05.485807Z","iopub.execute_input":"2025-04-05T21:00:05.486116Z","iopub.status.idle":"2025-04-05T21:00:05.544482Z","shell.execute_reply.started":"2025-04-05T21:00:05.486093Z","shell.execute_reply":"2025-04-05T21:00:05.543772Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Section 5: Train the Network**\n\nWe train the model by feeding the training data through the network and updating weights based on the loss.","metadata":{"id":"Ky9RmfrHMtbb"}},{"cell_type":"code","source":"for epoch in range(epochs):\n    model.train()  # Set model to training mode\n    running_loss = 0.0\n    for images, labels in train_loader:\n        images, labels = images.to('cuda'), labels.to('cuda')  # Move data to the appropriate device (CPU/GPU)\n        \n        optimizer.zero_grad()  # Clear previous gradients\n        \n        outputs = model(images)  # Perform forward pass through the model\n        \n        loss = criterion(outputs,labels)  # Calculate the loss using criterion\n        \n        loss.backward()  # Backpropagate the gradients\n        optimizer.step()  # Update model weights\n        \n        running_loss += loss.item()  # Accumulate the loss value\n    print(f'Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}')","metadata":{"id":"E1S16BXgOnJs","outputId":"800020fc-2145-41e8-80ec-1b6250868004","trusted":true,"execution":{"iopub.status.busy":"2025-04-05T21:00:11.143423Z","iopub.execute_input":"2025-04-05T21:00:11.1437Z","iopub.status.idle":"2025-04-05T21:00:33.80828Z","shell.execute_reply.started":"2025-04-05T21:00:11.143678Z","shell.execute_reply":"2025-04-05T21:00:33.807454Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Section 6: Perform Inference**\n\nAfter training, we evaluate the model on the test set to make predictions.","metadata":{"id":"8fWQDXfSMtil"}},{"cell_type":"code","source":"model.eval()  # Set model to evaluation mode\npredictions = []\ntrue_labels = []\n\nwith torch.no_grad():  # Disable gradient tracking for inference\n    for images, labels in test_loader:\n        images = images.to('cuda')  # Move images to the appropriate device\n        outputs = model(images)  # Forward pass through the model\n        _, predicted = torch.max(outputs, 1)  # Get predicted class with highest score\n        predictions.extend(predicted.cpu().numpy())  # Append predictions to the list\n        true_labels.extend(labels.numpy())  # Append true labels to the list","metadata":{"id":"6N8BJ76OOqpA","trusted":true,"execution":{"iopub.status.busy":"2025-04-05T21:02:09.024415Z","iopub.execute_input":"2025-04-05T21:02:09.024705Z","iopub.status.idle":"2025-04-05T21:02:09.245806Z","shell.execute_reply.started":"2025-04-05T21:02:09.024684Z","shell.execute_reply":"2025-04-05T21:02:09.245059Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Section 7: Output**\n\nFinally, we calculate the accuracy and visualize a sample prediction to assess the modelâ€™s performance.","metadata":{"id":"1om_rJxkMtmm"}},{"cell_type":"code","source":"# Calculate accuracy\naccuracy = np.mean(np.array(predictions) == np.array(true_labels))  # Compute mean of correct predictions\nprint(f'Test Accuracy: {accuracy:.4f}')\n\n# Visualize a sample prediction\nindex = 9  # Choose an index to visualize\nsample_img, sample_label = test_dataset[index]\nplt.imshow(sample_img.permute(1,2,0))  # Display the image (make sure to permute for correct format)\npred_label = predictions[index]\nplt.title(f'Predicted: {\"Tumor\" if pred_label == 1 else \"No Tumor\"}, True: {\"Tumor\" if sample_label == 1 else \"No Tumor\"}')\nplt.show()","metadata":{"id":"MTxcgFY5OtqY","outputId":"6bb0d5d0-4c38-4ad4-fa8c-ce87238d81d4","trusted":true,"execution":{"iopub.status.busy":"2025-04-05T21:04:43.983784Z","iopub.execute_input":"2025-04-05T21:04:43.984088Z","iopub.status.idle":"2025-04-05T21:04:44.158413Z","shell.execute_reply.started":"2025-04-05T21:04:43.984064Z","shell.execute_reply":"2025-04-05T21:04:44.157697Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}